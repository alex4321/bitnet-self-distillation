{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from bitnet_selfdistil import lm_losses_calculator, patch_model, TrainerModel\n",
    "from bitnet_selfdistil_utils import phi3_full_gradient_checkpoint_enable, MultiComponentLossTrainer\n",
    "from torch.optim import SGD\n",
    "from transformers import TrainingArguments, DataCollatorWithPadding\n",
    "from transformers.trainer import DEFAULT_PROGRESS_CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c830f8f89dc846a1a78d6b958d12f13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_to_chat_format(item):\n",
    "    roles = item[\"conversation\"][\"role\"]\n",
    "    contents = item[\"conversation\"][\"content\"]\n",
    "    return {\n",
    "        \"conversation\": [\n",
    "            {\"role\": role, \"content\": content}\n",
    "            for role, content in zip(roles, contents)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def apply_chat_template(item):\n",
    "    return {\n",
    "        \"conversation\": tokenizer.apply_chat_template(item[\"conversation\"], tokenize=False)\n",
    "    }\n",
    "\n",
    "\n",
    "def tokenize_conversation(item):\n",
    "    tokenized = tokenizer(item[\"conversation\"], return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "    input_ids = tokenized[\"input_ids\"].squeeze()\n",
    "    attention_mask = tokenized[\"attention_mask\"].squeeze()\n",
    "    item[\"input_ids\"] = input_ids\n",
    "    item[\"attention_mask\"] = attention_mask\n",
    "    item[\"labels\"] = input_ids\n",
    "    return item\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"alex43219/quant-text-dataset\",\n",
    "                       trust_remote_code=True,\n",
    "                       streaming=True)\n",
    "dataset = dataset.map(conversation_to_chat_format, batched=False) \\\n",
    "    .map(apply_chat_template, batched=False) \\\n",
    "    .map(tokenize_conversation, batched=False) \\\n",
    "    .remove_columns(['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the model I will use endless iterator on top of my dataset\n",
    "def _endless_iterator(dataset):\n",
    "    while True:\n",
    "        for sample in dataset:\n",
    "            yield sample\n",
    "\n",
    "\n",
    "class _EndlessDataset(IterableDataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        return _endless_iterator(self.dataset)\n",
    "\n",
    "\n",
    "dataset_train = _EndlessDataset(dataset[\"train\"])\n",
    "dataset_test = _EndlessDataset(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_STEPS = 8000\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 1\n",
    "MAX_FULL_LOSSES_LENGTH = 4096\n",
    "SAVE_EACH_N_STEPS = 4000\n",
    "MAX_STEPS = 40 * SAVE_EACH_N_STEPS\n",
    "MAX_GRAD_NORM = 5.0\n",
    "\n",
    "LOG_DIR = \"bitnet-selfdistil-tensorboard\"\n",
    "CHECKPOINT_DIRECTORY = \"phi-3-self-distillation-bitnet/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = phi3_full_gradient_checkpoint_enable(model)\n",
    "model = patch_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfdistill_model = TrainerModel(\n",
    "    model,\n",
    "    lm_losses_calculator(MAX_FULL_LOSSES_LENGTH),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    # Set up the optimizer with fused=True for performance benefits\n",
    "    return SGD(model.parameters(), lr=LR, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=CHECKPOINT_DIRECTORY,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    logging_dir=LOG_DIR,\n",
    "    logging_steps=50,\n",
    "    save_steps=SAVE_EACH_N_STEPS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    learning_rate=LR,\n",
    "    save_total_limit=10,\n",
    "    bf16=True,\n",
    "    logging_first_step=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    max_steps=MAX_STEPS,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = MultiComponentLossTrainer(\n",
    "    model=selfdistill_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(create_optimizer(selfdistill_model), None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfeba5a826044e29cd58d6ca21a76dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 78.76007843017578, 'loss_lm': 26.807697296142578, 'kldiv_loss': 25.89899444580078, 'hidden_state_loss': 26.053386688232422, 'epoch': 0}\n",
      "{'loss': 78.7601, 'grad_norm': 584.0, 'learning_rate': 1.2500000000000001e-08, 'epoch': 0.0}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 71.8530502319336, 'loss_lm': 23.828596115112305, 'kldiv_loss': 22.329914093017578, 'hidden_state_loss': 25.694541931152344, 'epoch': 0.0}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 76.82511138916016, 'loss_lm': 26.47493553161621, 'kldiv_loss': 24.32211685180664, 'hidden_state_loss': 26.028060913085938, 'epoch': 0.01}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 78.6412124633789, 'loss_lm': 26.98451042175293, 'kldiv_loss': 25.54534149169922, 'hidden_state_loss': 26.111356735229492, 'epoch': 0.01}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 76.56661987304688, 'loss_lm': 25.722864151000977, 'kldiv_loss': 24.76016616821289, 'hidden_state_loss': 26.08358383178711, 'epoch': 0.01}\n",
      "INPUT SHAPE torch.Size([1, 123])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 77.3727798461914, 'loss_lm': 26.37216567993164, 'kldiv_loss': 24.850330352783203, 'hidden_state_loss': 26.150285720825195, 'epoch': 0.01}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 78.30623626708984, 'loss_lm': 26.822134017944336, 'kldiv_loss': 25.484485626220703, 'hidden_state_loss': 25.999616622924805, 'epoch': 0.01}\n",
      "INPUT SHAPE torch.Size([1, 57])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 71.77859497070312, 'loss_lm': 23.378732681274414, 'kldiv_loss': 22.226455688476562, 'hidden_state_loss': 26.17340850830078, 'epoch': 0.02}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 75.98733520507812, 'loss_lm': 26.125682830810547, 'kldiv_loss': 23.955764770507812, 'hidden_state_loss': 25.905885696411133, 'epoch': 0.02}\n",
      "INPUT SHAPE torch.Size([1, 128])\n",
      "SETTING TEACHER MODE\n",
      "CALCULATING TEACHER OUTPUT\n",
      "CALCULATING STUDENT MODE\n",
      "CALCULATING STUDENT OUTPUT\n",
      "CALCULATING LOSSES\n",
      "FINISHED FORWARD\n",
      "{'loss': 74.4078369140625, 'loss_lm': 25.531862258911133, 'kldiv_loss': 22.80061149597168, 'hidden_state_loss': 26.07536506652832, 'epoch': 0.02}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}\n",
    "\n",
    "trainer.remove_callback(DEFAULT_PROGRESS_CALLBACK)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfdistill_model.model.model.layers[0].self_attn.o_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfdistill_model.model.model.layers[0].self_attn.o_proj.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfdistill_model.model.model.layers[0].self_attn.o_proj.delta_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfdistill_model.model.model.layers[0].self_attn.o_proj.delta_weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-distillation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
