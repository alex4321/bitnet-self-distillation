{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:36.629477Z",
     "start_time": "2024-10-23T01:30:34.801121Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from bitnet_selfdistil import lm_losses_calculator, ReLoRAConfig, ReLoRAEvents, ReloraTrainer, BitLinearWithLoRA\n",
    "from bitnet_selfdistill_utils import phi3_full_gradient_checkpoint_enable\n",
    "from torch.optim import AdamW"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:36.636Z",
     "start_time": "2024-10-23T01:30:36.633822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "DEVICE = \"cuda:0\"\n",
    "LORA_RANK = 128"
   ],
   "id": "ec7855fa5a5b8321",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:41.397386Z",
     "start_time": "2024-10-23T01:30:36.679957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=DEVICE,\n",
    ")"
   ],
   "id": "1b3765664a6aeec3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e811932bbc64fb49a9c0ea6aa2c1afa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:41.409548Z",
     "start_time": "2024-10-23T01:30:41.407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_generation(model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\",\n",
    "                }\n",
    "            ],\n",
    "            return_tensors=\"pt\",\n",
    "            add_generation_prompt=True\n",
    "        ).to(device=DEVICE)\n",
    "        generation_output = model.generate(input_ids=input_ids,\n",
    "                                           return_dict_in_generate=True,\n",
    "                                           output_scores=True,\n",
    "                                           max_length=100)\n",
    "        response = tokenizer.decode(generation_output.sequences[0][input_ids.shape[1]:])\n",
    "        print(response)"
   ],
   "id": "d6ab661d202301fc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.542822Z",
     "start_time": "2024-10-23T01:30:41.451900Z"
    }
   },
   "cell_type": "code",
   "source": "check_generation(model, tokenizer)",
   "id": "84b12ef616681779",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Bananas and dragonfruits can be combined in various delicious ways. Here are some creative recipes and ideas to enjoy these fruits together:\n",
      "\n",
      "1. **Banana Dragonfruit Smoothie**:\n",
      "   - Blend together one ripe banana, half a cup of dragonfruit puree, a cup of almond milk\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.616370Z",
     "start_time": "2024-10-23T01:30:44.614054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _global_lr(step):\n",
    "    if step < 2000:\n",
    "        return step / 2000\n",
    "    else:\n",
    "        return 1.0"
   ],
   "id": "64659da7315bfec3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.678598Z",
     "start_time": "2024-10-23T01:30:44.675320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _step_end(step, optimizer, losses, loss):\n",
    "    if step % 50 == 0:\n",
    "        print(f\"STEP {step}\")\n",
    "        for loss_name, loss_value in losses.items():\n",
    "            print(f\"{loss_name}: {loss_value.item():.4f}\")"
   ],
   "id": "f55b55f0f353d035",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.726511Z",
     "start_time": "2024-10-23T01:30:44.724231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _chunk_end(chunk, step):\n",
    "    print(f\"CHUNK {chunk} FINISHED AT STEP {step}\")"
   ],
   "id": "e2a63ebfcd79fa8d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.773494Z",
     "start_time": "2024-10-23T01:30:44.771031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relora_config = ReLoRAConfig(\n",
    "    blacklisted_modules=[\"lm_head\"],\n",
    "    lora_rank=128,\n",
    "    optimizer_type=AdamW,\n",
    "    optimizer_kwargs={\n",
    "        \"lr\": 1e-4,\n",
    "    },\n",
    "    reset_steps=1000,\n",
    "    chunk_warmup_steps=100,\n",
    "    lr_global=_global_lr,\n",
    ")"
   ],
   "id": "b057b6ab539e207c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.819868Z",
     "start_time": "2024-10-23T01:30:44.817343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relora_events = ReLoRAEvents(\n",
    "    on_step_end=_step_end,\n",
    "    on_chunk_end=_chunk_end,\n",
    ")"
   ],
   "id": "df044b9a77db557b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.868553Z",
     "start_time": "2024-10-23T01:30:44.865489Z"
    }
   },
   "cell_type": "code",
   "source": "model = phi3_full_gradient_checkpoint_enable(model)",
   "id": "adcbfe1afcd53fc8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.921155Z",
     "start_time": "2024-10-23T01:30:44.913527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = ReloraTrainer(\n",
    "    model=model,\n",
    "    relora_config=relora_config,\n",
    "    events=relora_events,\n",
    "    losses_calculator=lm_losses_calculator(4096),\n",
    "    max_steps=20000,\n",
    "    model_kwargs={\n",
    "        \"output_hidden_states\": True,\n",
    "    }\n",
    ")"
   ],
   "id": "45bc7366714f2f9c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:44.970834Z",
     "start_time": "2024-10-23T01:30:44.966492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = {\n",
    "    \"input_ids\": tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Certainly! Bananas and dragonfruits can be combined in a variety of delicious and creative ways. Here are some ideas:\\n\" + \\\n",
    "                           \"- Blended Smoothie:\\n\" + \\\n",
    "                           \"  Peel and cut both fruits into chunks and blend them with some yogurt or coconut milk for creaminess. Add a scoop of protein powder or a spoonful of peanut butter for extra protein and flavor.\"\n",
    "            }\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    ).to(device=DEVICE)\n",
    "}\n",
    "batch[\"labels\"] = batch[\"input_ids\"].clone()"
   ],
   "id": "8cd387718c2c981a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T01:30:45.017367Z",
     "start_time": "2024-10-23T01:30:45.014637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batches=[\n",
    "    batch\n",
    "    for _ in range(5000)\n",
    "]"
   ],
   "id": "3d669f1bc44d1ad2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-23T01:30:45.062426Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train(batches)",
   "id": "58807fc93ceb8d95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0\n",
      "loss_lm: 24.0062\n",
      "kldiv_loss: 23.2483\n",
      "hidden_state_loss: 26.0000\n",
      "loss: 73.2545\n",
      "STEP 50\n",
      "loss_lm: 23.9170\n",
      "kldiv_loss: 23.1573\n",
      "hidden_state_loss: 26.0000\n",
      "loss: 73.0743\n",
      "STEP 100\n",
      "loss_lm: 12.2565\n",
      "kldiv_loss: 11.5783\n",
      "hidden_state_loss: 25.7500\n",
      "loss: 49.5847\n",
      "STEP 150\n",
      "loss_lm: 8.7729\n",
      "kldiv_loss: 8.1127\n",
      "hidden_state_loss: 23.3750\n",
      "loss: 40.2605\n",
      "STEP 200\n",
      "loss_lm: 6.6762\n",
      "kldiv_loss: 6.1185\n",
      "hidden_state_loss: 20.7500\n",
      "loss: 33.5446\n",
      "STEP 250\n",
      "loss_lm: 5.1696\n",
      "kldiv_loss: 4.8269\n",
      "hidden_state_loss: 16.6250\n",
      "loss: 26.6214\n",
      "STEP 300\n",
      "loss_lm: 4.4452\n",
      "kldiv_loss: 4.3006\n",
      "hidden_state_loss: 13.1250\n",
      "loss: 21.8708\n",
      "STEP 350\n",
      "loss_lm: 3.7847\n",
      "kldiv_loss: 3.6965\n",
      "hidden_state_loss: 11.4375\n",
      "loss: 18.9187\n",
      "STEP 400\n",
      "loss_lm: 2.4683\n",
      "kldiv_loss: 2.4116\n",
      "hidden_state_loss: 10.6875\n",
      "loss: 15.5674\n",
      "STEP 450\n",
      "loss_lm: 1.4710\n",
      "kldiv_loss: 1.6508\n",
      "hidden_state_loss: 10.0625\n",
      "loss: 13.1843\n",
      "STEP 500\n",
      "loss_lm: 1.0462\n",
      "kldiv_loss: 1.1664\n",
      "hidden_state_loss: 9.6875\n",
      "loss: 11.9001\n",
      "STEP 550\n",
      "loss_lm: 0.6907\n",
      "kldiv_loss: 0.9026\n",
      "hidden_state_loss: 8.7500\n",
      "loss: 10.3433\n",
      "STEP 600\n",
      "loss_lm: 0.5647\n",
      "kldiv_loss: 0.8194\n",
      "hidden_state_loss: 8.5000\n",
      "loss: 9.8841\n",
      "STEP 650\n",
      "loss_lm: 0.6261\n",
      "kldiv_loss: 0.7587\n",
      "hidden_state_loss: 8.1875\n",
      "loss: 9.5723\n",
      "STEP 700\n",
      "loss_lm: 0.4659\n",
      "kldiv_loss: 0.7516\n",
      "hidden_state_loss: 7.7188\n",
      "loss: 8.9363\n",
      "STEP 750\n",
      "loss_lm: 0.5033\n",
      "kldiv_loss: 0.6794\n",
      "hidden_state_loss: 7.4688\n",
      "loss: 8.6514\n",
      "STEP 800\n",
      "loss_lm: 0.3655\n",
      "kldiv_loss: 0.5844\n",
      "hidden_state_loss: 6.9375\n",
      "loss: 7.8874\n",
      "STEP 850\n",
      "loss_lm: 0.2458\n",
      "kldiv_loss: 0.6449\n",
      "hidden_state_loss: 6.8438\n",
      "loss: 7.7345\n",
      "STEP 900\n",
      "loss_lm: 0.5130\n",
      "kldiv_loss: 0.6346\n",
      "hidden_state_loss: 6.8125\n",
      "loss: 7.9601\n",
      "STEP 950\n",
      "loss_lm: 0.2870\n",
      "kldiv_loss: 0.5036\n",
      "hidden_state_loss: 6.3125\n",
      "loss: 7.1031\n",
      "CHUNK 0 FINISHED AT STEP 1000\n",
      "STEP 1000\n",
      "loss_lm: 0.2536\n",
      "kldiv_loss: 0.5525\n",
      "hidden_state_loss: 6.0938\n",
      "loss: 6.8998\n",
      "STEP 1050\n",
      "loss_lm: 0.2207\n",
      "kldiv_loss: 0.4829\n",
      "hidden_state_loss: 5.9375\n",
      "loss: 6.6411\n",
      "STEP 1100\n",
      "loss_lm: 0.2470\n",
      "kldiv_loss: 0.3410\n",
      "hidden_state_loss: 5.7500\n",
      "loss: 6.3381\n",
      "STEP 1150\n",
      "loss_lm: 0.2290\n",
      "kldiv_loss: 0.3646\n",
      "hidden_state_loss: 5.7500\n",
      "loss: 6.3437\n",
      "STEP 1200\n",
      "loss_lm: 0.2685\n",
      "kldiv_loss: 0.3305\n",
      "hidden_state_loss: 5.7812\n",
      "loss: 6.3802\n",
      "STEP 1250\n",
      "loss_lm: 0.2603\n",
      "kldiv_loss: 0.3691\n",
      "hidden_state_loss: 5.6562\n",
      "loss: 6.2857\n",
      "STEP 1300\n",
      "loss_lm: 0.2809\n",
      "kldiv_loss: 0.3428\n",
      "hidden_state_loss: 5.4688\n",
      "loss: 6.0925\n",
      "STEP 1350\n",
      "loss_lm: 0.2839\n",
      "kldiv_loss: 0.3033\n",
      "hidden_state_loss: 5.2500\n",
      "loss: 5.8372\n",
      "STEP 1400\n",
      "loss_lm: 0.3107\n",
      "kldiv_loss: 0.3294\n",
      "hidden_state_loss: 5.1250\n",
      "loss: 5.7652\n",
      "STEP 1450\n",
      "loss_lm: 0.2395\n",
      "kldiv_loss: 0.3734\n",
      "hidden_state_loss: 4.8125\n",
      "loss: 5.4255\n",
      "STEP 1500\n",
      "loss_lm: 0.2523\n",
      "kldiv_loss: 0.3207\n",
      "hidden_state_loss: 4.6250\n",
      "loss: 5.1980\n",
      "STEP 1550\n",
      "loss_lm: 0.2542\n",
      "kldiv_loss: 0.2833\n",
      "hidden_state_loss: 4.4062\n",
      "loss: 4.9438\n",
      "STEP 1600\n",
      "loss_lm: 0.2955\n",
      "kldiv_loss: 0.2403\n",
      "hidden_state_loss: 4.1875\n",
      "loss: 4.7233\n",
      "STEP 1650\n",
      "loss_lm: 0.2634\n",
      "kldiv_loss: 0.2934\n",
      "hidden_state_loss: 3.9688\n",
      "loss: 4.5256\n",
      "STEP 1700\n",
      "loss_lm: 0.2862\n",
      "kldiv_loss: 0.2241\n",
      "hidden_state_loss: 3.7812\n",
      "loss: 4.2915\n",
      "STEP 1750\n",
      "loss_lm: 0.2506\n",
      "kldiv_loss: 0.2745\n",
      "hidden_state_loss: 3.7969\n",
      "loss: 4.3220\n",
      "STEP 1800\n",
      "loss_lm: 0.2295\n",
      "kldiv_loss: 0.2492\n",
      "hidden_state_loss: 3.5312\n",
      "loss: 4.0099\n",
      "STEP 1850\n",
      "loss_lm: 0.2447\n",
      "kldiv_loss: 0.2671\n",
      "hidden_state_loss: 3.4062\n",
      "loss: 3.9180\n",
      "STEP 1900\n",
      "loss_lm: 0.2459\n",
      "kldiv_loss: 0.2265\n",
      "hidden_state_loss: 3.2812\n",
      "loss: 3.7537\n",
      "STEP 1950\n",
      "loss_lm: 0.2093\n",
      "kldiv_loss: 0.2930\n",
      "hidden_state_loss: 3.2188\n",
      "loss: 3.7210\n",
      "CHUNK 1 FINISHED AT STEP 2000\n",
      "STEP 2000\n",
      "loss_lm: 0.2435\n",
      "kldiv_loss: 0.2160\n",
      "hidden_state_loss: 3.1250\n",
      "loss: 3.5846\n",
      "STEP 2050\n",
      "loss_lm: 0.2295\n",
      "kldiv_loss: 0.2144\n",
      "hidden_state_loss: 3.0000\n",
      "loss: 3.4439\n",
      "STEP 2100\n",
      "loss_lm: 0.2163\n",
      "kldiv_loss: 0.1983\n",
      "hidden_state_loss: 2.8125\n",
      "loss: 3.2271\n",
      "STEP 2150\n",
      "loss_lm: 0.2188\n",
      "kldiv_loss: 0.1963\n",
      "hidden_state_loss: 2.8125\n",
      "loss: 3.2276\n",
      "STEP 2200\n",
      "loss_lm: 0.2290\n",
      "kldiv_loss: 0.1922\n",
      "hidden_state_loss: 2.8438\n",
      "loss: 3.2649\n",
      "STEP 2250\n",
      "loss_lm: 0.2413\n",
      "kldiv_loss: 0.1776\n",
      "hidden_state_loss: 2.8125\n",
      "loss: 3.2313\n",
      "STEP 2300\n",
      "loss_lm: 0.2295\n",
      "kldiv_loss: 0.1858\n",
      "hidden_state_loss: 2.7812\n",
      "loss: 3.1966\n",
      "STEP 2350\n",
      "loss_lm: 0.2023\n",
      "kldiv_loss: 0.2299\n",
      "hidden_state_loss: 2.8750\n",
      "loss: 3.3072\n",
      "STEP 2400\n",
      "loss_lm: 0.2309\n",
      "kldiv_loss: 0.2041\n",
      "hidden_state_loss: 2.7500\n",
      "loss: 3.1850\n",
      "STEP 2450\n",
      "loss_lm: 0.2436\n",
      "kldiv_loss: 0.1851\n",
      "hidden_state_loss: 2.7031\n",
      "loss: 3.1318\n",
      "STEP 2500\n",
      "loss_lm: 0.2012\n",
      "kldiv_loss: 0.2530\n",
      "hidden_state_loss: 2.7031\n",
      "loss: 3.1573\n",
      "STEP 2550\n",
      "loss_lm: 0.2125\n",
      "kldiv_loss: 0.2210\n",
      "hidden_state_loss: 2.6406\n",
      "loss: 3.0742\n",
      "STEP 2600\n",
      "loss_lm: 0.2410\n",
      "kldiv_loss: 0.1903\n",
      "hidden_state_loss: 2.5938\n",
      "loss: 3.0250\n",
      "STEP 2650\n",
      "loss_lm: 0.2263\n",
      "kldiv_loss: 0.2212\n",
      "hidden_state_loss: 2.5781\n",
      "loss: 3.0257\n",
      "STEP 2700\n",
      "loss_lm: 0.2386\n",
      "kldiv_loss: 0.2134\n",
      "hidden_state_loss: 2.4531\n",
      "loss: 2.9052\n",
      "STEP 2750\n",
      "loss_lm: 0.2285\n",
      "kldiv_loss: 0.2135\n",
      "hidden_state_loss: 2.4375\n",
      "loss: 2.8795\n",
      "STEP 2800\n",
      "loss_lm: 0.2364\n",
      "kldiv_loss: 0.2256\n",
      "hidden_state_loss: 2.3750\n",
      "loss: 2.8370\n",
      "STEP 2850\n",
      "loss_lm: 0.2656\n",
      "kldiv_loss: 0.1725\n",
      "hidden_state_loss: 2.2344\n",
      "loss: 2.6725\n",
      "STEP 2900\n",
      "loss_lm: 0.2325\n",
      "kldiv_loss: 0.2013\n",
      "hidden_state_loss: 2.1875\n",
      "loss: 2.6213\n",
      "STEP 2950\n",
      "loss_lm: 0.2224\n",
      "kldiv_loss: 0.2129\n",
      "hidden_state_loss: 2.0625\n",
      "loss: 2.4977\n",
      "CHUNK 2 FINISHED AT STEP 3000\n",
      "STEP 3000\n",
      "loss_lm: 0.2251\n",
      "kldiv_loss: 0.2030\n",
      "hidden_state_loss: 1.9922\n",
      "loss: 2.4203\n",
      "STEP 3050\n",
      "loss_lm: 0.2081\n",
      "kldiv_loss: 0.2051\n",
      "hidden_state_loss: 1.8906\n",
      "loss: 2.3038\n",
      "STEP 3100\n",
      "loss_lm: 0.2132\n",
      "kldiv_loss: 0.1855\n",
      "hidden_state_loss: 1.8359\n",
      "loss: 2.2346\n",
      "STEP 3150\n",
      "loss_lm: 0.2116\n",
      "kldiv_loss: 0.1885\n",
      "hidden_state_loss: 1.8359\n",
      "loss: 2.2360\n",
      "STEP 3200\n",
      "loss_lm: 0.2389\n",
      "kldiv_loss: 0.1631\n",
      "hidden_state_loss: 1.8516\n",
      "loss: 2.2535\n",
      "STEP 3250\n",
      "loss_lm: 0.2176\n",
      "kldiv_loss: 0.1834\n",
      "hidden_state_loss: 1.8516\n",
      "loss: 2.2526\n",
      "STEP 3300\n",
      "loss_lm: 0.2400\n",
      "kldiv_loss: 0.1716\n",
      "hidden_state_loss: 1.8281\n",
      "loss: 2.2398\n",
      "STEP 3350\n",
      "loss_lm: 0.2194\n",
      "kldiv_loss: 0.1882\n",
      "hidden_state_loss: 1.8516\n",
      "loss: 2.2592\n",
      "STEP 3400\n",
      "loss_lm: 0.2224\n",
      "kldiv_loss: 0.1874\n",
      "hidden_state_loss: 1.8281\n",
      "loss: 2.2379\n",
      "STEP 3450\n",
      "loss_lm: 0.2106\n",
      "kldiv_loss: 0.1982\n",
      "hidden_state_loss: 1.7734\n",
      "loss: 2.1822\n",
      "STEP 3500\n",
      "loss_lm: 0.2218\n",
      "kldiv_loss: 0.1869\n",
      "hidden_state_loss: 1.7578\n",
      "loss: 2.1664\n",
      "STEP 3550\n",
      "loss_lm: 0.2053\n",
      "kldiv_loss: 0.2136\n",
      "hidden_state_loss: 1.7578\n",
      "loss: 2.1767\n",
      "STEP 3600\n",
      "loss_lm: 0.2170\n",
      "kldiv_loss: 0.1967\n",
      "hidden_state_loss: 1.7266\n",
      "loss: 2.1402\n",
      "STEP 3650\n",
      "loss_lm: 0.2218\n",
      "kldiv_loss: 0.1892\n",
      "hidden_state_loss: 1.6953\n",
      "loss: 2.1063\n",
      "STEP 3700\n",
      "loss_lm: 0.2402\n",
      "kldiv_loss: 0.1712\n",
      "hidden_state_loss: 1.6953\n",
      "loss: 2.1067\n",
      "STEP 3750\n",
      "loss_lm: 0.2267\n",
      "kldiv_loss: 0.1894\n",
      "hidden_state_loss: 1.6641\n",
      "loss: 2.0802\n",
      "STEP 3800\n",
      "loss_lm: 0.2270\n",
      "kldiv_loss: 0.2031\n",
      "hidden_state_loss: 1.6406\n",
      "loss: 2.0707\n",
      "STEP 3850\n",
      "loss_lm: 0.2219\n",
      "kldiv_loss: 0.1939\n",
      "hidden_state_loss: 1.5859\n",
      "loss: 2.0018\n",
      "STEP 3900\n",
      "loss_lm: 0.2192\n",
      "kldiv_loss: 0.2010\n",
      "hidden_state_loss: 1.5625\n",
      "loss: 1.9827\n",
      "STEP 3950\n",
      "loss_lm: 0.2411\n",
      "kldiv_loss: 0.1837\n",
      "hidden_state_loss: 1.5078\n",
      "loss: 1.9326\n",
      "CHUNK 3 FINISHED AT STEP 4000\n",
      "STEP 4000\n",
      "loss_lm: 0.2216\n",
      "kldiv_loss: 0.2036\n",
      "hidden_state_loss: 1.4531\n",
      "loss: 1.8783\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain(batches)\n",
      "File \u001B[0;32m~/PycharmProjects/bitnet-selfdistill/bitnet_selfdistil/relora_trainer.py:102\u001B[0m, in \u001B[0;36mReloraTrainer.train\u001B[0;34m(self, dataloader_train)\u001B[0m\n\u001B[1;32m    100\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, batches \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chunks(dataloader_train)):\n\u001B[0;32m--> 102\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chunk_train(i, step, batches)\n\u001B[1;32m    103\u001B[0m     step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batches)\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevents\u001B[38;5;241m.\u001B[39mon_chunk_end \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/bitnet-selfdistill/bitnet_selfdistil/relora_trainer.py:90\u001B[0m, in \u001B[0;36mReloraTrainer._chunk_train\u001B[0;34m(self, index, start_step, batches)\u001B[0m\n\u001B[1;32m     88\u001B[0m student_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m     89\u001B[0m loss_components, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosses_calculator(teacher_outputs, student_outputs)\n\u001B[0;32m---> 90\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     91\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     92\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    580\u001B[0m     )\n\u001B[0;32m--> 581\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    582\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    583\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m _engine_run_backward(\n\u001B[1;32m    348\u001B[0m     tensors,\n\u001B[1;32m    349\u001B[0m     grad_tensors_,\n\u001B[1;32m    350\u001B[0m     retain_graph,\n\u001B[1;32m    351\u001B[0m     create_graph,\n\u001B[1;32m    352\u001B[0m     inputs,\n\u001B[1;32m    353\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    354\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    355\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weights = {}\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, BitLinearWithLoRA):\n",
    "        weight = module.get_bitnet_weight().detach().cpu()\n",
    "        weights[f\"{name}.weight\"] = weight"
   ],
   "id": "4743a5537a732ae4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "weights[\"model.layers.0.self_attn.o_proj.weight\"].shape",
   "id": "e865d3422b17f976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "70e0faa9a984633a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "872135494f75904d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=DEVICE,\n",
    ")"
   ],
   "id": "f374b0af642dabae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "weights[\"model.layers.0.self_attn.o_proj.weight\"].dtype",
   "id": "4bfe011345885838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "    dict(model.state_dict(), **weights),\n",
    "    strict=False\n",
    ")"
   ],
   "id": "dd7c50e7cd488188",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "set(weights[\"model.layers.0.self_attn.o_proj.weight\"].float().numpy().ravel())",
   "id": "68f9a6b5f75bbc18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "set( (model.state_dict()[\"model.layers.0.self_attn.o_proj.weight\"] * 1).detach().cpu().float().numpy().ravel() )",
   "id": "37bb114143363036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "check_generation(model, tokenizer)",
   "id": "1c7bad5d7874c994",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
