{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:11:21.275859Z",
     "start_time": "2024-10-23T00:11:21.273032Z"
    }
   },
   "source": [
    "import gc\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from bitnet_selfdistil import lm_losses_calculator, ReLoRAConfig, ReLoRAEvents, ReloraTrainer, BitLinearWithLoRA\n",
    "from torch.optim import AdamW"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:22.268098Z",
     "start_time": "2024-10-22T22:29:22.266114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "DEVICE = \"cuda:0\"\n",
    "LORA_RANK = 128"
   ],
   "id": "ec7855fa5a5b8321",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:27.831406Z",
     "start_time": "2024-10-22T22:29:22.320429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=DEVICE,\n",
    ")"
   ],
   "id": "1b3765664a6aeec3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04aab8208bce46c2a3f080211a5250e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:27.846308Z",
     "start_time": "2024-10-22T22:29:27.842571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_generation(model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\",\n",
    "                }\n",
    "            ],\n",
    "            return_tensors=\"pt\",\n",
    "            add_generation_prompt=True\n",
    "        ).to(device=DEVICE)\n",
    "        generation_output = model.generate(input_ids=input_ids,\n",
    "                                           return_dict_in_generate=True,\n",
    "                                           output_scores=True,\n",
    "                                           max_length=100)\n",
    "        response = tokenizer.decode(generation_output.sequences[0][input_ids.shape[1]:])\n",
    "        print(response)"
   ],
   "id": "d6ab661d202301fc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.470378Z",
     "start_time": "2024-10-22T22:29:27.884761Z"
    }
   },
   "cell_type": "code",
   "source": "check_generation(model, tokenizer)",
   "id": "84b12ef616681779",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Bananas and dragonfruits can be combined in various delicious ways. Here are some creative recipes and ideas to enjoy these fruits together:\n",
      "\n",
      "1. **Banana Dragonfruit Smoothie**:\n",
      "   - Blend together one ripe banana, half a cup of dragonfruit puree, a cup of almond milk\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.483352Z",
     "start_time": "2024-10-22T22:29:31.481128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _global_lr(step):\n",
    "    if step < 2000:\n",
    "        return step / 2000\n",
    "    else:\n",
    "        return 1.0"
   ],
   "id": "64659da7315bfec3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.534158Z",
     "start_time": "2024-10-22T22:29:31.531782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _step_end(step, optimizer, losses, loss):\n",
    "    if step % 50 == 0:\n",
    "        print(f\"STEP {step}\")\n",
    "        for loss_name, loss_value in losses.items():\n",
    "            print(f\"{loss_name}: {loss_value.item():.4f}\")"
   ],
   "id": "f55b55f0f353d035",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.575957Z",
     "start_time": "2024-10-22T22:29:31.573554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _chunk_end(chunk, step):\n",
    "    print(f\"CHUNK {chunk} FINISHED AT STEP {step}\")"
   ],
   "id": "e2a63ebfcd79fa8d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.622565Z",
     "start_time": "2024-10-22T22:29:31.619467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relora_config = ReLoRAConfig(\n",
    "    blacklisted_modules=[\"lm_head\"],\n",
    "    lora_rank=128,\n",
    "    optimizer_type=AdamW,\n",
    "    optimizer_kwargs={\n",
    "        \"lr\": 1e-4,\n",
    "    },\n",
    "    reset_steps=1000,\n",
    "    chunk_warmup_steps=100,\n",
    "    lr_global=_global_lr,\n",
    ")"
   ],
   "id": "b057b6ab539e207c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.668082Z",
     "start_time": "2024-10-22T22:29:31.665339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relora_events = ReLoRAEvents(\n",
    "    on_step_end=_step_end,\n",
    "    on_chunk_end=_chunk_end,\n",
    ")"
   ],
   "id": "df044b9a77db557b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.721183Z",
     "start_time": "2024-10-22T22:29:31.712318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.checkpoint import checkpoint\n",
    "from transformers.models.phi3.modeling_phi3 import Phi3DecoderLayer"
   ],
   "id": "924e081d9dcdb157",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.764347Z",
     "start_time": "2024-10-22T22:29:31.758398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def patched_phi3RMS_norm_forward(module):\n",
    "    def forward(hidden_states):\n",
    "        assert (hidden_states.dtype == torch.bfloat16) or (hidden_states.dtype == torch.float32)\n",
    "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + module.variance_epsilon)\n",
    "        return module.weight * hidden_states\n",
    "    \n",
    "    return forward\n",
    "\n",
    "def make_new_forward(module):\n",
    "    def forward(hidden_states,\n",
    "                attention_mask = None,\n",
    "                position_ids = None,\n",
    "                past_key_value = None,\n",
    "                output_attentions = False,\n",
    "                use_cache = False,\n",
    "                cache_position = None,\n",
    "                **kwargs):\n",
    "        #print(f\"hidden_states.requires_grad: {hidden_states.requires_grad}\")\n",
    "        result = checkpoint(\n",
    "            lambda *args: Phi3DecoderLayer.forward(module, *args, **kwargs),\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            position_ids,\n",
    "            past_key_value,\n",
    "            output_attentions,\n",
    "            use_cache,\n",
    "            cache_position,\n",
    "            use_reentrant=True\n",
    "        )\n",
    "        #print(f\"result[0].requires_grad: {result[0].requires_grad}\")\n",
    "        return result\n",
    "    \n",
    "    return forward\n",
    "\n",
    "model.enable_input_require_grads()\n",
    "for module in model.model.layers:\n",
    "    module.forward = make_new_forward(module)\n",
    "    module.input_layernorm.forward = patched_phi3RMS_norm_forward(module.input_layernorm)\n",
    "    module.post_attention_layernorm.forward = patched_phi3RMS_norm_forward(module.post_attention_layernorm)"
   ],
   "id": "adcbfe1afcd53fc8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.821142Z",
     "start_time": "2024-10-22T22:29:31.807526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = ReloraTrainer(\n",
    "    model=model,\n",
    "    relora_config=relora_config,\n",
    "    events=relora_events,\n",
    "    losses_calculator=lm_losses_calculator(4096),\n",
    "    max_steps=20000,\n",
    "    model_kwargs={\n",
    "        \"output_hidden_states\": True,\n",
    "    }\n",
    ")"
   ],
   "id": "45bc7366714f2f9c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.867359Z",
     "start_time": "2024-10-22T22:29:31.863336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = {\n",
    "    \"input_ids\": tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Certainly! Bananas and dragonfruits can be combined in a variety of delicious and creative ways. Here are some ideas:\\n\" + \\\n",
    "                           \"- Blended Smoothie:\\n\" + \\\n",
    "                           \"  Peel and cut both fruits into chunks and blend them with some yogurt or coconut milk for creaminess. Add a scoop of protein powder or a spoonful of peanut butter for extra protein and flavor.\"\n",
    "            }\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    ).to(device=DEVICE)\n",
    "}\n",
    "batch[\"labels\"] = batch[\"input_ids\"].clone()"
   ],
   "id": "8cd387718c2c981a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:29:31.912853Z",
     "start_time": "2024-10-22T22:29:31.909481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batches=[\n",
    "    batch\n",
    "    for _ in range(20000)\n",
    "]"
   ],
   "id": "3d669f1bc44d1ad2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-22T22:29:31.956575Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train(batches)",
   "id": "58807fc93ceb8d95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex4321/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0\n",
      "loss_lm: 24.0062\n",
      "kldiv_loss: 23.2483\n",
      "hidden_state_loss: 26.0000\n",
      "loss: 73.2545\n",
      "STEP 50\n",
      "loss_lm: 23.9170\n",
      "kldiv_loss: 23.1573\n",
      "hidden_state_loss: 26.0000\n",
      "loss: 73.0743\n",
      "STEP 100\n",
      "loss_lm: 12.2565\n",
      "kldiv_loss: 11.5783\n",
      "hidden_state_loss: 25.7500\n",
      "loss: 49.5847\n",
      "STEP 150\n",
      "loss_lm: 8.7729\n",
      "kldiv_loss: 8.1127\n",
      "hidden_state_loss: 23.3750\n",
      "loss: 40.2605\n",
      "STEP 200\n",
      "loss_lm: 6.6762\n",
      "kldiv_loss: 6.1185\n",
      "hidden_state_loss: 20.7500\n",
      "loss: 33.5446\n",
      "STEP 250\n",
      "loss_lm: 5.1696\n",
      "kldiv_loss: 4.8269\n",
      "hidden_state_loss: 16.6250\n",
      "loss: 26.6214\n",
      "STEP 300\n",
      "loss_lm: 4.4452\n",
      "kldiv_loss: 4.3006\n",
      "hidden_state_loss: 13.1250\n",
      "loss: 21.8708\n",
      "STEP 350\n",
      "loss_lm: 3.7847\n",
      "kldiv_loss: 3.6965\n",
      "hidden_state_loss: 11.4375\n",
      "loss: 18.9187\n",
      "STEP 400\n",
      "loss_lm: 2.4683\n",
      "kldiv_loss: 2.4116\n",
      "hidden_state_loss: 10.6875\n",
      "loss: 15.5674\n",
      "STEP 450\n",
      "loss_lm: 1.4710\n",
      "kldiv_loss: 1.6508\n",
      "hidden_state_loss: 10.0625\n",
      "loss: 13.1843\n",
      "STEP 500\n",
      "loss_lm: 1.0462\n",
      "kldiv_loss: 1.1664\n",
      "hidden_state_loss: 9.6875\n",
      "loss: 11.9001\n",
      "STEP 550\n",
      "loss_lm: 0.6907\n",
      "kldiv_loss: 0.9026\n",
      "hidden_state_loss: 8.7500\n",
      "loss: 10.3433\n",
      "STEP 600\n",
      "loss_lm: 0.5647\n",
      "kldiv_loss: 0.8194\n",
      "hidden_state_loss: 8.5000\n",
      "loss: 9.8841\n",
      "STEP 650\n",
      "loss_lm: 0.6261\n",
      "kldiv_loss: 0.7587\n",
      "hidden_state_loss: 8.1875\n",
      "loss: 9.5723\n",
      "STEP 700\n",
      "loss_lm: 0.4659\n",
      "kldiv_loss: 0.7516\n",
      "hidden_state_loss: 7.7188\n",
      "loss: 8.9363\n",
      "STEP 750\n",
      "loss_lm: 0.5033\n",
      "kldiv_loss: 0.6794\n",
      "hidden_state_loss: 7.4688\n",
      "loss: 8.6514\n",
      "STEP 800\n",
      "loss_lm: 0.3655\n",
      "kldiv_loss: 0.5844\n",
      "hidden_state_loss: 6.9375\n",
      "loss: 7.8874\n",
      "STEP 850\n",
      "loss_lm: 0.2458\n",
      "kldiv_loss: 0.6449\n",
      "hidden_state_loss: 6.8438\n",
      "loss: 7.7345\n",
      "STEP 900\n",
      "loss_lm: 0.5130\n",
      "kldiv_loss: 0.6346\n",
      "hidden_state_loss: 6.8125\n",
      "loss: 7.9601\n",
      "STEP 950\n",
      "loss_lm: 0.2870\n",
      "kldiv_loss: 0.5036\n",
      "hidden_state_loss: 6.3125\n",
      "loss: 7.1031\n",
      "CHUNK 0 FINISHED AT STEP 1000\n",
      "STEP 1000\n",
      "loss_lm: 0.2536\n",
      "kldiv_loss: 0.5525\n",
      "hidden_state_loss: 6.0938\n",
      "loss: 6.8998\n",
      "STEP 1050\n",
      "loss_lm: 0.2207\n",
      "kldiv_loss: 0.4829\n",
      "hidden_state_loss: 5.9375\n",
      "loss: 6.6411\n",
      "STEP 1100\n",
      "loss_lm: 0.2470\n",
      "kldiv_loss: 0.3410\n",
      "hidden_state_loss: 5.7500\n",
      "loss: 6.3381\n",
      "STEP 1150\n",
      "loss_lm: 0.2290\n",
      "kldiv_loss: 0.3646\n",
      "hidden_state_loss: 5.7500\n",
      "loss: 6.3437\n",
      "STEP 1200\n",
      "loss_lm: 0.2685\n",
      "kldiv_loss: 0.3305\n",
      "hidden_state_loss: 5.7812\n",
      "loss: 6.3802\n",
      "STEP 1250\n",
      "loss_lm: 0.2603\n",
      "kldiv_loss: 0.3691\n",
      "hidden_state_loss: 5.6562\n",
      "loss: 6.2857\n",
      "STEP 1300\n",
      "loss_lm: 0.2809\n",
      "kldiv_loss: 0.3428\n",
      "hidden_state_loss: 5.4688\n",
      "loss: 6.0925\n",
      "STEP 1350\n",
      "loss_lm: 0.2839\n",
      "kldiv_loss: 0.3033\n",
      "hidden_state_loss: 5.2500\n",
      "loss: 5.8372\n",
      "STEP 1400\n",
      "loss_lm: 0.3107\n",
      "kldiv_loss: 0.3294\n",
      "hidden_state_loss: 5.1250\n",
      "loss: 5.7652\n",
      "STEP 1450\n",
      "loss_lm: 0.2395\n",
      "kldiv_loss: 0.3734\n",
      "hidden_state_loss: 4.8125\n",
      "loss: 5.4255\n",
      "STEP 1500\n",
      "loss_lm: 0.2523\n",
      "kldiv_loss: 0.3207\n",
      "hidden_state_loss: 4.6250\n",
      "loss: 5.1980\n",
      "STEP 1550\n",
      "loss_lm: 0.2542\n",
      "kldiv_loss: 0.2833\n",
      "hidden_state_loss: 4.4062\n",
      "loss: 4.9438\n",
      "STEP 1600\n",
      "loss_lm: 0.2955\n",
      "kldiv_loss: 0.2403\n",
      "hidden_state_loss: 4.1875\n",
      "loss: 4.7233\n",
      "STEP 1650\n",
      "loss_lm: 0.2634\n",
      "kldiv_loss: 0.2934\n",
      "hidden_state_loss: 3.9688\n",
      "loss: 4.5256\n",
      "STEP 1700\n",
      "loss_lm: 0.2862\n",
      "kldiv_loss: 0.2241\n",
      "hidden_state_loss: 3.7812\n",
      "loss: 4.2915\n",
      "STEP 1750\n",
      "loss_lm: 0.2506\n",
      "kldiv_loss: 0.2745\n",
      "hidden_state_loss: 3.7969\n",
      "loss: 4.3220\n",
      "STEP 1800\n",
      "loss_lm: 0.2295\n",
      "kldiv_loss: 0.2492\n",
      "hidden_state_loss: 3.5312\n",
      "loss: 4.0099\n",
      "STEP 1850\n",
      "loss_lm: 0.2447\n",
      "kldiv_loss: 0.2671\n",
      "hidden_state_loss: 3.4062\n",
      "loss: 3.9180\n",
      "STEP 1900\n",
      "loss_lm: 0.2459\n",
      "kldiv_loss: 0.2265\n",
      "hidden_state_loss: 3.2812\n",
      "loss: 3.7537\n",
      "STEP 1950\n",
      "loss_lm: 0.2093\n",
      "kldiv_loss: 0.2930\n",
      "hidden_state_loss: 3.2188\n",
      "loss: 3.7210\n",
      "CHUNK 1 FINISHED AT STEP 2000\n",
      "STEP 2000\n",
      "loss_lm: 0.2435\n",
      "kldiv_loss: 0.2160\n",
      "hidden_state_loss: 3.1250\n",
      "loss: 3.5846\n",
      "STEP 2050\n",
      "loss_lm: 0.2295\n",
      "kldiv_loss: 0.2144\n",
      "hidden_state_loss: 3.0000\n",
      "loss: 3.4439\n",
      "STEP 2100\n",
      "loss_lm: 0.2163\n",
      "kldiv_loss: 0.1983\n",
      "hidden_state_loss: 2.8125\n",
      "loss: 3.2271\n",
      "STEP 2150\n",
      "loss_lm: 0.2188\n",
      "kldiv_loss: 0.1963\n",
      "hidden_state_loss: 2.8125\n",
      "loss: 3.2276\n",
      "STEP 2200\n",
      "loss_lm: 0.2290\n",
      "kldiv_loss: 0.1922\n",
      "hidden_state_loss: 2.8438\n",
      "loss: 3.2649\n",
      "STEP 2250\n",
      "loss_lm: 0.2413\n",
      "kldiv_loss: 0.1776\n",
      "hidden_state_loss: 2.8125\n",
      "loss: 3.2313\n",
      "STEP 2300\n",
      "loss_lm: 0.2295\n",
      "kldiv_loss: 0.1858\n",
      "hidden_state_loss: 2.7812\n",
      "loss: 3.1966\n",
      "STEP 2350\n",
      "loss_lm: 0.2023\n",
      "kldiv_loss: 0.2299\n",
      "hidden_state_loss: 2.8750\n",
      "loss: 3.3072\n",
      "STEP 2400\n",
      "loss_lm: 0.2309\n",
      "kldiv_loss: 0.2041\n",
      "hidden_state_loss: 2.7500\n",
      "loss: 3.1850\n",
      "STEP 2450\n",
      "loss_lm: 0.2436\n",
      "kldiv_loss: 0.1851\n",
      "hidden_state_loss: 2.7031\n",
      "loss: 3.1318\n",
      "STEP 2500\n",
      "loss_lm: 0.2012\n",
      "kldiv_loss: 0.2530\n",
      "hidden_state_loss: 2.7031\n",
      "loss: 3.1573\n",
      "STEP 2550\n",
      "loss_lm: 0.2125\n",
      "kldiv_loss: 0.2210\n",
      "hidden_state_loss: 2.6406\n",
      "loss: 3.0742\n",
      "STEP 2600\n",
      "loss_lm: 0.2410\n",
      "kldiv_loss: 0.1903\n",
      "hidden_state_loss: 2.5938\n",
      "loss: 3.0250\n",
      "STEP 2650\n",
      "loss_lm: 0.2263\n",
      "kldiv_loss: 0.2212\n",
      "hidden_state_loss: 2.5781\n",
      "loss: 3.0257\n",
      "STEP 2700\n",
      "loss_lm: 0.2386\n",
      "kldiv_loss: 0.2134\n",
      "hidden_state_loss: 2.4531\n",
      "loss: 2.9052\n",
      "STEP 2750\n",
      "loss_lm: 0.2285\n",
      "kldiv_loss: 0.2135\n",
      "hidden_state_loss: 2.4375\n",
      "loss: 2.8795\n",
      "STEP 2800\n",
      "loss_lm: 0.2364\n",
      "kldiv_loss: 0.2256\n",
      "hidden_state_loss: 2.3750\n",
      "loss: 2.8370\n",
      "STEP 2850\n",
      "loss_lm: 0.2656\n",
      "kldiv_loss: 0.1725\n",
      "hidden_state_loss: 2.2344\n",
      "loss: 2.6725\n",
      "STEP 2900\n",
      "loss_lm: 0.2325\n",
      "kldiv_loss: 0.2013\n",
      "hidden_state_loss: 2.1875\n",
      "loss: 2.6213\n",
      "STEP 2950\n",
      "loss_lm: 0.2224\n",
      "kldiv_loss: 0.2129\n",
      "hidden_state_loss: 2.0625\n",
      "loss: 2.4977\n",
      "CHUNK 2 FINISHED AT STEP 3000\n",
      "STEP 3000\n",
      "loss_lm: 0.2251\n",
      "kldiv_loss: 0.2030\n",
      "hidden_state_loss: 1.9922\n",
      "loss: 2.4203\n",
      "STEP 3050\n",
      "loss_lm: 0.2081\n",
      "kldiv_loss: 0.2051\n",
      "hidden_state_loss: 1.8906\n",
      "loss: 2.3038\n",
      "STEP 3100\n",
      "loss_lm: 0.2132\n",
      "kldiv_loss: 0.1855\n",
      "hidden_state_loss: 1.8359\n",
      "loss: 2.2346\n",
      "STEP 3150\n",
      "loss_lm: 0.2116\n",
      "kldiv_loss: 0.1885\n",
      "hidden_state_loss: 1.8359\n",
      "loss: 2.2360\n",
      "STEP 3200\n",
      "loss_lm: 0.2389\n",
      "kldiv_loss: 0.1631\n",
      "hidden_state_loss: 1.8516\n",
      "loss: 2.2535\n",
      "STEP 3250\n",
      "loss_lm: 0.2176\n",
      "kldiv_loss: 0.1834\n",
      "hidden_state_loss: 1.8516\n",
      "loss: 2.2526\n",
      "STEP 3300\n",
      "loss_lm: 0.2400\n",
      "kldiv_loss: 0.1716\n",
      "hidden_state_loss: 1.8281\n",
      "loss: 2.2398\n",
      "STEP 3350\n",
      "loss_lm: 0.2194\n",
      "kldiv_loss: 0.1882\n",
      "hidden_state_loss: 1.8516\n",
      "loss: 2.2592\n",
      "STEP 3400\n",
      "loss_lm: 0.2224\n",
      "kldiv_loss: 0.1874\n",
      "hidden_state_loss: 1.8281\n",
      "loss: 2.2379\n",
      "STEP 3450\n",
      "loss_lm: 0.2106\n",
      "kldiv_loss: 0.1982\n",
      "hidden_state_loss: 1.7734\n",
      "loss: 2.1822\n",
      "STEP 3500\n",
      "loss_lm: 0.2218\n",
      "kldiv_loss: 0.1869\n",
      "hidden_state_loss: 1.7578\n",
      "loss: 2.1664\n",
      "STEP 3550\n",
      "loss_lm: 0.2053\n",
      "kldiv_loss: 0.2136\n",
      "hidden_state_loss: 1.7578\n",
      "loss: 2.1767\n",
      "STEP 3600\n",
      "loss_lm: 0.2170\n",
      "kldiv_loss: 0.1967\n",
      "hidden_state_loss: 1.7266\n",
      "loss: 2.1402\n",
      "STEP 3650\n",
      "loss_lm: 0.2218\n",
      "kldiv_loss: 0.1892\n",
      "hidden_state_loss: 1.6953\n",
      "loss: 2.1063\n",
      "STEP 3700\n",
      "loss_lm: 0.2402\n",
      "kldiv_loss: 0.1712\n",
      "hidden_state_loss: 1.6953\n",
      "loss: 2.1067\n",
      "STEP 3750\n",
      "loss_lm: 0.2267\n",
      "kldiv_loss: 0.1894\n",
      "hidden_state_loss: 1.6641\n",
      "loss: 2.0802\n",
      "STEP 3800\n",
      "loss_lm: 0.2270\n",
      "kldiv_loss: 0.2031\n",
      "hidden_state_loss: 1.6406\n",
      "loss: 2.0707\n",
      "STEP 3850\n",
      "loss_lm: 0.2219\n",
      "kldiv_loss: 0.1939\n",
      "hidden_state_loss: 1.5859\n",
      "loss: 2.0018\n",
      "STEP 3900\n",
      "loss_lm: 0.2192\n",
      "kldiv_loss: 0.2010\n",
      "hidden_state_loss: 1.5625\n",
      "loss: 1.9827\n",
      "STEP 3950\n",
      "loss_lm: 0.2411\n",
      "kldiv_loss: 0.1837\n",
      "hidden_state_loss: 1.5078\n",
      "loss: 1.9326\n",
      "CHUNK 3 FINISHED AT STEP 4000\n",
      "STEP 4000\n",
      "loss_lm: 0.2216\n",
      "kldiv_loss: 0.2036\n",
      "hidden_state_loss: 1.4531\n",
      "loss: 1.8783\n",
      "STEP 4050\n",
      "loss_lm: 0.2116\n",
      "kldiv_loss: 0.1988\n",
      "hidden_state_loss: 1.3594\n",
      "loss: 1.7698\n",
      "STEP 4100\n",
      "loss_lm: 0.2224\n",
      "kldiv_loss: 0.1717\n",
      "hidden_state_loss: 1.3281\n",
      "loss: 1.7223\n",
      "STEP 4150\n",
      "loss_lm: 0.2269\n",
      "kldiv_loss: 0.1666\n",
      "hidden_state_loss: 1.3125\n",
      "loss: 1.7060\n",
      "STEP 4200\n",
      "loss_lm: 0.2183\n",
      "kldiv_loss: 0.1775\n",
      "hidden_state_loss: 1.3359\n",
      "loss: 1.7317\n",
      "STEP 4250\n",
      "loss_lm: 0.2308\n",
      "kldiv_loss: 0.1651\n",
      "hidden_state_loss: 1.3125\n",
      "loss: 1.7085\n",
      "STEP 4300\n",
      "loss_lm: 0.2096\n",
      "kldiv_loss: 0.1914\n",
      "hidden_state_loss: 1.3203\n",
      "loss: 1.7213\n",
      "STEP 4350\n",
      "loss_lm: 0.2217\n",
      "kldiv_loss: 0.1786\n",
      "hidden_state_loss: 1.3281\n",
      "loss: 1.7284\n",
      "STEP 4400\n",
      "loss_lm: 0.2161\n",
      "kldiv_loss: 0.1843\n",
      "hidden_state_loss: 1.3203\n",
      "loss: 1.7207\n",
      "STEP 4450\n",
      "loss_lm: 0.2293\n",
      "kldiv_loss: 0.1708\n",
      "hidden_state_loss: 1.3125\n",
      "loss: 1.7126\n",
      "STEP 4500\n",
      "loss_lm: 0.2363\n",
      "kldiv_loss: 0.1730\n",
      "hidden_state_loss: 1.3203\n",
      "loss: 1.7297\n",
      "STEP 4550\n",
      "loss_lm: 0.2339\n",
      "kldiv_loss: 0.1742\n",
      "hidden_state_loss: 1.3047\n",
      "loss: 1.7128\n",
      "STEP 4600\n",
      "loss_lm: 0.2108\n",
      "kldiv_loss: 0.1928\n",
      "hidden_state_loss: 1.2891\n",
      "loss: 1.6926\n",
      "STEP 4650\n",
      "loss_lm: 0.2211\n",
      "kldiv_loss: 0.1861\n",
      "hidden_state_loss: 1.2891\n",
      "loss: 1.6962\n",
      "STEP 4700\n",
      "loss_lm: 0.2046\n",
      "kldiv_loss: 0.2017\n",
      "hidden_state_loss: 1.2500\n",
      "loss: 1.6563\n",
      "STEP 4750\n",
      "loss_lm: 0.2274\n",
      "kldiv_loss: 0.1816\n",
      "hidden_state_loss: 1.2422\n",
      "loss: 1.6512\n",
      "STEP 4800\n",
      "loss_lm: 0.2234\n",
      "kldiv_loss: 0.1877\n",
      "hidden_state_loss: 1.2266\n",
      "loss: 1.6376\n",
      "STEP 4850\n",
      "loss_lm: 0.2347\n",
      "kldiv_loss: 0.1717\n",
      "hidden_state_loss: 1.2188\n",
      "loss: 1.6251\n",
      "STEP 4900\n",
      "loss_lm: 0.2155\n",
      "kldiv_loss: 0.2017\n",
      "hidden_state_loss: 1.2188\n",
      "loss: 1.6359\n",
      "STEP 4950\n",
      "loss_lm: 0.2221\n",
      "kldiv_loss: 0.1923\n",
      "hidden_state_loss: 1.1875\n",
      "loss: 1.6018\n",
      "CHUNK 4 FINISHED AT STEP 5000\n",
      "STEP 5000\n",
      "loss_lm: 0.2309\n",
      "kldiv_loss: 0.1837\n",
      "hidden_state_loss: 1.1719\n",
      "loss: 1.5864\n",
      "STEP 5050\n",
      "loss_lm: 0.2185\n",
      "kldiv_loss: 0.1836\n",
      "hidden_state_loss: 1.0938\n",
      "loss: 1.4958\n",
      "STEP 5100\n",
      "loss_lm: 0.2219\n",
      "kldiv_loss: 0.1711\n",
      "hidden_state_loss: 1.0703\n",
      "loss: 1.4633\n",
      "STEP 5150\n",
      "loss_lm: 0.2227\n",
      "kldiv_loss: 0.1701\n",
      "hidden_state_loss: 1.0859\n",
      "loss: 1.4788\n",
      "STEP 5200\n",
      "loss_lm: 0.2085\n",
      "kldiv_loss: 0.1879\n",
      "hidden_state_loss: 1.0859\n",
      "loss: 1.4823\n",
      "STEP 5250\n",
      "loss_lm: 0.2171\n",
      "kldiv_loss: 0.1778\n",
      "hidden_state_loss: 1.0859\n",
      "loss: 1.4809\n",
      "STEP 5300\n",
      "loss_lm: 0.2208\n",
      "kldiv_loss: 0.1736\n",
      "hidden_state_loss: 1.0938\n",
      "loss: 1.4882\n",
      "STEP 5350\n",
      "loss_lm: 0.2228\n",
      "kldiv_loss: 0.1742\n",
      "hidden_state_loss: 1.0703\n",
      "loss: 1.4673\n",
      "STEP 5400\n",
      "loss_lm: 0.2266\n",
      "kldiv_loss: 0.1713\n",
      "hidden_state_loss: 1.0781\n",
      "loss: 1.4760\n",
      "STEP 5450\n",
      "loss_lm: 0.2250\n",
      "kldiv_loss: 0.1747\n",
      "hidden_state_loss: 1.0859\n",
      "loss: 1.4857\n",
      "STEP 5500\n",
      "loss_lm: 0.2141\n",
      "kldiv_loss: 0.1859\n",
      "hidden_state_loss: 1.0938\n",
      "loss: 1.4937\n",
      "STEP 5550\n",
      "loss_lm: 0.2375\n",
      "kldiv_loss: 0.1627\n",
      "hidden_state_loss: 1.0703\n",
      "loss: 1.4704\n",
      "STEP 5600\n",
      "loss_lm: 0.2335\n",
      "kldiv_loss: 0.1694\n",
      "hidden_state_loss: 1.0781\n",
      "loss: 1.4810\n",
      "STEP 5650\n",
      "loss_lm: 0.2470\n",
      "kldiv_loss: 0.1583\n",
      "hidden_state_loss: 1.0469\n",
      "loss: 1.4522\n",
      "STEP 5700\n",
      "loss_lm: 0.2235\n",
      "kldiv_loss: 0.1788\n",
      "hidden_state_loss: 1.0547\n",
      "loss: 1.4569\n",
      "STEP 5750\n",
      "loss_lm: 0.2268\n",
      "kldiv_loss: 0.1794\n",
      "hidden_state_loss: 1.0547\n",
      "loss: 1.4609\n",
      "STEP 5800\n",
      "loss_lm: 0.2135\n",
      "kldiv_loss: 0.1938\n",
      "hidden_state_loss: 1.0469\n",
      "loss: 1.4542\n",
      "STEP 5850\n",
      "loss_lm: 0.2191\n",
      "kldiv_loss: 0.1868\n",
      "hidden_state_loss: 1.0234\n",
      "loss: 1.4293\n",
      "STEP 5900\n",
      "loss_lm: 0.2431\n",
      "kldiv_loss: 0.1674\n",
      "hidden_state_loss: 1.0391\n",
      "loss: 1.4496\n",
      "STEP 5950\n",
      "loss_lm: 0.2290\n",
      "kldiv_loss: 0.1757\n",
      "hidden_state_loss: 1.0000\n",
      "loss: 1.4047\n",
      "CHUNK 5 FINISHED AT STEP 6000\n",
      "STEP 6000\n",
      "loss_lm: 0.2436\n",
      "kldiv_loss: 0.1639\n",
      "hidden_state_loss: 0.9727\n",
      "loss: 1.3801\n",
      "STEP 6050\n",
      "loss_lm: 0.2196\n",
      "kldiv_loss: 0.1772\n",
      "hidden_state_loss: 0.9414\n",
      "loss: 1.3381\n",
      "STEP 6100\n",
      "loss_lm: 0.2192\n",
      "kldiv_loss: 0.1723\n",
      "hidden_state_loss: 0.9062\n",
      "loss: 1.2977\n",
      "STEP 6150\n",
      "loss_lm: 0.2225\n",
      "kldiv_loss: 0.1703\n",
      "hidden_state_loss: 0.9180\n",
      "loss: 1.3108\n",
      "STEP 6200\n",
      "loss_lm: 0.2081\n",
      "kldiv_loss: 0.1860\n",
      "hidden_state_loss: 0.9141\n",
      "loss: 1.3082\n",
      "STEP 6250\n",
      "loss_lm: 0.2215\n",
      "kldiv_loss: 0.1734\n",
      "hidden_state_loss: 0.9180\n",
      "loss: 1.3129\n",
      "STEP 6300\n",
      "loss_lm: 0.2223\n",
      "kldiv_loss: 0.1716\n",
      "hidden_state_loss: 0.9219\n",
      "loss: 1.3158\n",
      "STEP 6350\n",
      "loss_lm: 0.2131\n",
      "kldiv_loss: 0.1815\n",
      "hidden_state_loss: 0.9141\n",
      "loss: 1.3086\n",
      "STEP 6400\n",
      "loss_lm: 0.2229\n",
      "kldiv_loss: 0.1738\n",
      "hidden_state_loss: 0.9258\n",
      "loss: 1.3225\n",
      "STEP 6450\n",
      "loss_lm: 0.2154\n",
      "kldiv_loss: 0.1821\n",
      "hidden_state_loss: 0.9336\n",
      "loss: 1.3310\n",
      "STEP 6500\n",
      "loss_lm: 0.2228\n",
      "kldiv_loss: 0.1759\n",
      "hidden_state_loss: 0.9102\n",
      "loss: 1.3089\n",
      "STEP 6550\n",
      "loss_lm: 0.2329\n",
      "kldiv_loss: 0.1679\n",
      "hidden_state_loss: 0.9141\n",
      "loss: 1.3149\n",
      "STEP 6600\n",
      "loss_lm: 0.2217\n",
      "kldiv_loss: 0.1797\n",
      "hidden_state_loss: 0.9180\n",
      "loss: 1.3194\n",
      "STEP 6650\n",
      "loss_lm: 0.2359\n",
      "kldiv_loss: 0.1639\n",
      "hidden_state_loss: 0.9219\n",
      "loss: 1.3216\n",
      "STEP 6700\n",
      "loss_lm: 0.2267\n",
      "kldiv_loss: 0.1760\n",
      "hidden_state_loss: 0.9062\n",
      "loss: 1.3089\n",
      "STEP 6750\n",
      "loss_lm: 0.2362\n",
      "kldiv_loss: 0.1703\n",
      "hidden_state_loss: 0.8984\n",
      "loss: 1.3050\n",
      "STEP 6800\n",
      "loss_lm: 0.2340\n",
      "kldiv_loss: 0.1745\n",
      "hidden_state_loss: 0.9141\n",
      "loss: 1.3226\n",
      "STEP 6850\n",
      "loss_lm: 0.2093\n",
      "kldiv_loss: 0.1936\n",
      "hidden_state_loss: 0.8867\n",
      "loss: 1.2896\n",
      "STEP 6900\n",
      "loss_lm: 0.2235\n",
      "kldiv_loss: 0.1876\n",
      "hidden_state_loss: 0.9023\n",
      "loss: 1.3134\n",
      "STEP 6950\n",
      "loss_lm: 0.2134\n",
      "kldiv_loss: 0.1897\n",
      "hidden_state_loss: 0.8906\n",
      "loss: 1.2937\n",
      "CHUNK 6 FINISHED AT STEP 7000\n",
      "STEP 7000\n",
      "loss_lm: 0.2198\n",
      "kldiv_loss: 0.1930\n",
      "hidden_state_loss: 0.8828\n",
      "loss: 1.2955\n",
      "STEP 7050\n",
      "loss_lm: 0.2225\n",
      "kldiv_loss: 0.1754\n",
      "hidden_state_loss: 0.8750\n",
      "loss: 1.2729\n",
      "STEP 7100\n",
      "loss_lm: 0.2173\n",
      "kldiv_loss: 0.1741\n",
      "hidden_state_loss: 0.8242\n",
      "loss: 1.2155\n",
      "STEP 7150\n",
      "loss_lm: 0.2208\n",
      "kldiv_loss: 0.1709\n",
      "hidden_state_loss: 0.8203\n",
      "loss: 1.2121\n",
      "STEP 7200\n",
      "loss_lm: 0.2235\n",
      "kldiv_loss: 0.1704\n",
      "hidden_state_loss: 0.8281\n",
      "loss: 1.2220\n",
      "STEP 7250\n",
      "loss_lm: 0.2120\n",
      "kldiv_loss: 0.1825\n",
      "hidden_state_loss: 0.8281\n",
      "loss: 1.2226\n",
      "STEP 7300\n",
      "loss_lm: 0.2210\n",
      "kldiv_loss: 0.1744\n",
      "hidden_state_loss: 0.8281\n",
      "loss: 1.2235\n",
      "STEP 7350\n",
      "loss_lm: 0.2183\n",
      "kldiv_loss: 0.1771\n",
      "hidden_state_loss: 0.8477\n",
      "loss: 1.2431\n",
      "STEP 7400\n",
      "loss_lm: 0.2214\n",
      "kldiv_loss: 0.1729\n",
      "hidden_state_loss: 0.8242\n",
      "loss: 1.2185\n",
      "STEP 7450\n",
      "loss_lm: 0.2130\n",
      "kldiv_loss: 0.1832\n",
      "hidden_state_loss: 0.8281\n",
      "loss: 1.2243\n",
      "STEP 7500\n",
      "loss_lm: 0.2128\n",
      "kldiv_loss: 0.1834\n",
      "hidden_state_loss: 0.8242\n",
      "loss: 1.2204\n",
      "STEP 7550\n",
      "loss_lm: 0.2344\n",
      "kldiv_loss: 0.1640\n",
      "hidden_state_loss: 0.8242\n",
      "loss: 1.2226\n",
      "STEP 7600\n",
      "loss_lm: 0.2313\n",
      "kldiv_loss: 0.1732\n",
      "hidden_state_loss: 0.8203\n",
      "loss: 1.2248\n",
      "STEP 7650\n",
      "loss_lm: 0.2254\n",
      "kldiv_loss: 0.1761\n",
      "hidden_state_loss: 0.8281\n",
      "loss: 1.2296\n",
      "STEP 7700\n",
      "loss_lm: 0.2252\n",
      "kldiv_loss: 0.1732\n",
      "hidden_state_loss: 0.8320\n",
      "loss: 1.2305\n",
      "STEP 7750\n",
      "loss_lm: 0.2287\n",
      "kldiv_loss: 0.1730\n",
      "hidden_state_loss: 0.8438\n",
      "loss: 1.2455\n",
      "STEP 7800\n",
      "loss_lm: 0.2171\n",
      "kldiv_loss: 0.1845\n",
      "hidden_state_loss: 0.8320\n",
      "loss: 1.2336\n",
      "STEP 7850\n",
      "loss_lm: 0.2258\n",
      "kldiv_loss: 0.1770\n",
      "hidden_state_loss: 0.8594\n",
      "loss: 1.2622\n",
      "STEP 7900\n",
      "loss_lm: 0.2128\n",
      "kldiv_loss: 0.1920\n",
      "hidden_state_loss: 0.8281\n",
      "loss: 1.2330\n",
      "STEP 7950\n",
      "loss_lm: 0.2217\n",
      "kldiv_loss: 0.1872\n",
      "hidden_state_loss: 0.8438\n",
      "loss: 1.2526\n",
      "CHUNK 7 FINISHED AT STEP 8000\n",
      "STEP 8000\n",
      "loss_lm: 0.2533\n",
      "kldiv_loss: 0.1814\n",
      "hidden_state_loss: 1.1172\n",
      "loss: 1.5519\n",
      "STEP 8050\n",
      "loss_lm: 0.2383\n",
      "kldiv_loss: 0.1802\n",
      "hidden_state_loss: 1.0781\n",
      "loss: 1.4966\n",
      "STEP 8100\n",
      "loss_lm: 0.2174\n",
      "kldiv_loss: 0.1780\n",
      "hidden_state_loss: 0.9766\n",
      "loss: 1.3720\n",
      "STEP 8150\n",
      "loss_lm: 0.2189\n",
      "kldiv_loss: 0.1742\n",
      "hidden_state_loss: 0.9180\n",
      "loss: 1.3110\n",
      "STEP 8200\n",
      "loss_lm: 0.2231\n",
      "kldiv_loss: 0.1685\n",
      "hidden_state_loss: 0.8867\n",
      "loss: 1.2783\n",
      "STEP 8250\n",
      "loss_lm: 0.2180\n",
      "kldiv_loss: 0.1743\n",
      "hidden_state_loss: 0.8594\n",
      "loss: 1.2517\n",
      "STEP 8300\n",
      "loss_lm: 0.2163\n",
      "kldiv_loss: 0.1773\n",
      "hidden_state_loss: 0.8516\n",
      "loss: 1.2452\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain(batches)\n",
      "File \u001B[0;32m~/PycharmProjects/bitnet-selfdistill/bitnet_selfdistil/relora_trainer.py:100\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(self, dataloader_train)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataloader_train):\n\u001B[0;32m--> 100\u001B[0m     step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, batches \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chunks(dataloader_train)):\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chunk_train(i, step, batches)\n",
      "File \u001B[0;32m~/PycharmProjects/bitnet-selfdistill/bitnet_selfdistil/relora_trainer.py:90\u001B[0m, in \u001B[0;36mReloraTrainer._chunk_train\u001B[0;34m(self, index, start_step, batches)\u001B[0m\n\u001B[1;32m     88\u001B[0m student_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m     89\u001B[0m loss_components, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosses_calculator(teacher_outputs, student_outputs)\n\u001B[0;32m---> 90\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     91\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     92\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    580\u001B[0m     )\n\u001B[0;32m--> 581\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    582\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    583\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m _engine_run_backward(\n\u001B[1;32m    348\u001B[0m     tensors,\n\u001B[1;32m    349\u001B[0m     grad_tensors_,\n\u001B[1;32m    350\u001B[0m     retain_graph,\n\u001B[1;32m    351\u001B[0m     create_graph,\n\u001B[1;32m    352\u001B[0m     inputs,\n\u001B[1;32m    353\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    354\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    355\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/quant-distillation/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:13:07.094153Z",
     "start_time": "2024-10-23T00:13:02.649871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = {}\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, BitLinearWithLoRA):\n",
    "        weight = module.get_bitnet_weight().detach().cpu()\n",
    "        weights[f\"{name}.weight\"] = weight"
   ],
   "id": "4743a5537a732ae4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:13:33.867774Z",
     "start_time": "2024-10-23T00:13:33.864381Z"
    }
   },
   "cell_type": "code",
   "source": "weights[\"model.layers.0.self_attn.o_proj.weight\"].shape",
   "id": "e865d3422b17f976",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 3072])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:14:05.560557Z",
     "start_time": "2024-10-23T00:14:05.380301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "del model, trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "70e0faa9a984633a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:15:03.099319Z",
     "start_time": "2024-10-23T00:15:02.596351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "872135494f75904d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:15:41.867514Z",
     "start_time": "2024-10-23T00:15:34.700637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=DEVICE,\n",
    ")"
   ],
   "id": "f374b0af642dabae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75c92eff67bc44ee84ff73de7a9e30cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:16:28.650357Z",
     "start_time": "2024-10-23T00:16:28.646933Z"
    }
   },
   "cell_type": "code",
   "source": "weights[\"model.layers.0.self_attn.o_proj.weight\"].dtype",
   "id": "4bfe011345885838",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:17:03.584534Z",
     "start_time": "2024-10-23T00:17:02.717794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(\n",
    "    dict(model.state_dict(), **weights),\n",
    "    strict=False\n",
    ")"
   ],
   "id": "dd7c50e7cd488188",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:17:30.053476Z",
     "start_time": "2024-10-23T00:17:29.364029Z"
    }
   },
   "cell_type": "code",
   "source": "set(weights[\"model.layers.0.self_attn.o_proj.weight\"].float().numpy().ravel())",
   "id": "68f9a6b5f75bbc18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.013061523, -0.0, 0.013061523}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:18:22.201037Z",
     "start_time": "2024-10-23T00:18:21.463196Z"
    }
   },
   "cell_type": "code",
   "source": "set( (model.state_dict()[\"model.layers.0.self_attn.o_proj.weight\"] * 1).detach().cpu().float().numpy().ravel() )",
   "id": "37bb114143363036",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.013061523, -0.0, 0.013061523}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T00:18:40.240517Z",
     "start_time": "2024-10-23T00:18:37.638343Z"
    }
   },
   "cell_type": "code",
   "source": "check_generation(model, tokenizer)",
   "id": "1c7bad5d7874c994",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Bananas and dragonfruits can be combined in a variety of delicious and creative ways. Here are some ideas:\n",
      "\n",
      "\n",
      "- Blended Smoothie:\n",
      "  Comel and cut both fruits into chunks and blend them with some yogurt or coconut milk for a scoop of protein powder, a hand of hogurt\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
